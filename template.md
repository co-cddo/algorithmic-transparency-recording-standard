# Algorithmic transparency template

Use this form to provide information on how you use algorithmic tools to support decisions.

You must fill in both sections of the template. For the:

- tier 1 information, provide a short non-technical description of your algorithmic tool, and an overview of what the tool is and why the tool’s being used
- tier 2 information, provide more detailed technical information, such as specific details on how your tool works and the data the tool uses

Inside each tier, the numbers next to each section correspond to the numbers in the [algorithmic transparency data standard](/template_table.md).

## Tier 1 information

### How you’re using the algorithmic tool
Explain:

- how your tool works
- how your tool is incorporated into your decision making process

### Why you’re using the algorithmic tool
Explain:

- what problem you’re aiming to solve using the tool, and how it’s solving the problem
- your justification or rationale for using the tool
- how people can find out more about the tool or ask a question - including offline options and a contact email address of the responsible organisation, team or contact person

## Tier 2 information

### Who owns and has responsibility for the algorithmic tool
List who’s accountable for deploying your tool, including:

- your organisation (1.1)
- the team responsible for the tool (1.2)
- the senior responsible owner (1.3)
- your external supplier or any third parties involved, if the tool has been developed externally (1.4)
- the Companies House number of your external supplier (1.5)
- the role of the external supplier (1.6)
- the terms of their access to any government data (1.7)

### What the tool’s for
Describe the scope of the tool, what it’s been designed for and what it’s not intended for.

Expand your justification for using the tool, for example:

- describe what the tool has been designed for and not designed for, including purposes people may wrongly think the tool will be used for (2.1)
- provide a list of benefits - value for money, efficiency or ease for the individual (2.2)
- list non-algorithmic alternatives you considered, if this applies to your project, or a description of your decision-making process before you introduced the tool (2.3)

List the tool’s technical specifications, including:

- the type of model, for example an expert system or deep neural network (2.4)
- how regularly the tool is used - for example the number of decisions made per month, or number of citizens interacting with the tool (2.5)
- the phase - whether the tool is in the idea, design, development, production, or retired stage including the date and time it was created and any updates (2.6)
- the maintenance and review schedule, for example specific detail on when and how a human reviews or checks the automated decision (2.7)
- the system architecture (2.8)

### How the tool affects decision making
Explain how the tool is integrated into the process, and what influence the tool has on the decision making process. (3.1)

Explain how humans have oversight of the tool, including:

- how much information the tool provides to the decision maker, and what the information is (3.2)
- the decisions humans take in the overall process, including options for humans reviewing the tool (3.3)
- training that people deploying and using the tool must take, if this applies to your project (3.4)

Explain your appeal and review process. Describe how you’re letting members of the public review or appeal a decision. (3.5)

### Data
List and describe:

- the datasets you’ve used to train the model
- the datasets the model is or will be deployed on

Add links to the datasets if you can.

Include:

- the name of the datasets you used, if applicable (4.1)
- an overview of the data used to train and run the tool, including a description of which categories were used for training, testing or operating the model - for example ‘age’, ‘address’ and so on (4.2)
- the URL for the datasets you’ve used, if available (4.3)
- how and why you collect data, or how and why data was originally collected by someone else (4.4)
- the data sharing agreements you have in place (4.5)
- details on who has or will have access to this data and how long the data’s stored for, and under what circumstances (4.6)

### Impact assessments
List the impact assessments you’ve done, for example:

- Data Protection Impact Assessment
- algorithmic impact assessment
- ethical assessment
- equality impact assessment

For each assessment, add:

- the assessment name (5.1)
- a description of the impact assessment conducted (5.2)
- the date you completed the assessment (5.3)
- a link to the assessment or a summary of the assessment, if available (5.4)

### Risks
Provide a detailed description of common risks for your tool, including:

- the names of the common risks (5.5)
- a description of each identified risk (5.6)
For example:

- potential harm from the tool being used in a way it was not meant or built for
- creation of biased results, including through training data that is not representative or contains biases
- arbitrariness and functionality, such as the tool providing unfair or incorrect decisions

### Mitigations
Provide a detailed description of actions you’ve taken to mitigate the risks in your ‘Risks’ section. (5.7)
